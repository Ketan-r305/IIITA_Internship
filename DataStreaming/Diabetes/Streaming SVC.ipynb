{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "understood-reality",
   "metadata": {},
   "outputs": [],
   "source": [
    "# important modules\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import Normalizer\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.tuning import CrossValidatorModel\n",
    "from pyspark.ml import Pipeline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "swiss-focus",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating sparkContext and sparkSession\n",
    "sc = SparkContext.getOrCreate(SparkConf().setMaster(\"local[*]\"))\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "musical-gibson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the csv file\n",
    "df = (spark.read\n",
    "          .format(\"csv\")\n",
    "          .option('header', 'true')\n",
    "          .load(\"./datasets/training.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "monthly-carol",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting important columns\n",
    "columns  = df.columns\n",
    "\n",
    "dataset = df.select(col(columns[0]).cast('float'),\n",
    "                    col(columns[1]).cast('float'),\n",
    "                    col(columns[2]).cast('string'),\n",
    "                    col(columns[3]).cast('float'),\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "worthy-coast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature transformation\n",
    "indexer = StringIndexer(inputCol=\"code\", outputCol=\"codeIndex\")\n",
    "encoder = OneHotEncoder(inputCol=\"codeIndex\", outputCol=\"codeVec\")\n",
    "vectorAssembler = VectorAssembler(inputCols=['value','codeVec'],\n",
    "                                  outputCol=\"features\")\n",
    "#normalizer = Normalizer(inputCol=\"features\", outputCol=\"features_norm\", p=1.0)\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"features_norm\")\n",
    "pipeline = Pipeline(stages=[indexer, encoder, vectorAssembler, scaler])\n",
    "model = pipeline.fit(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "pressed-measure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading pre-trained model\n",
    "path= r'./SavedModel/svc_model'\n",
    "lr_model = CrossValidatorModel.read().load(path)\n",
    "lr = lr_model.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "metric-industry",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = [] #list to store the true labels\n",
    "prediction = [] #list to store the predicted labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adjustable-balloon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tp(label,prediction) :\n",
    "    '''\n",
    "    Positive class is 0\n",
    "    '''\n",
    "    total_positive_instances_indexes = label[label.values == 0.0].index\n",
    "    prediction_instances = prediction[total_positive_instances_indexes]\n",
    "    true_labels= prediction_instances[prediction_instances.values == 0.0]\n",
    "    return len(true_labels)\n",
    "\n",
    "\n",
    "def tn(label,prediction) :\n",
    "    '''\n",
    "    Negative Class is 1\n",
    "    '''\n",
    "    total_negative_instances_indexes = label[label.values == 1.0].index\n",
    "    prediction_instances = prediction[total_negative_instances_indexes]\n",
    "    true_labels= prediction_instances[prediction_instances.values == 1.0]\n",
    "    return len(true_labels)\n",
    "\n",
    "\n",
    "def fp(label,prediction) :\n",
    "\n",
    "    '''\n",
    "    Positive class is 0\n",
    "    '''\n",
    "    total_positive_instances_indexes = label[label.values == 0.0].index\n",
    "    prediction_instances = prediction[total_positive_instances_indexes]\n",
    "    true_labels= prediction_instances[prediction_instances.values == 0.0]\n",
    "    return len(prediction_instances) - len(true_labels)\n",
    "\n",
    "\n",
    "def fn(label,prediction) :\n",
    "    '''\n",
    "    Negative Class is 1\n",
    "    '''\n",
    "    total_negative_instances_indexes = label[label.values == 1.0].index\n",
    "    prediction_instances = prediction[total_negative_instances_indexes]\n",
    "    true_labels= prediction_instances[prediction_instances.values == 1.0]\n",
    "    return len(prediction_instances) - len(true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "attended-frame",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(labels,predictions) :\n",
    "    _tp = tp(labels,predictions)\n",
    "    _tn = tn(labels,predictions)\n",
    "    _fp = fp(labels,predictions)\n",
    "    _fn = fn(labels,predictions)\n",
    "    \n",
    "    return ((_tp+_tn)/(_tp+_tn+_fp+_fn))\n",
    "\n",
    "def precision(labels,predictions) : \n",
    "    _tp = tp(labels,predictions)\n",
    "    _fp = fp(labels,predictions)\n",
    "    \n",
    "    return (_tp/(_tp+_fp))\n",
    "\n",
    "def recall(labels,predictions) : \n",
    "    _tp = tp(labels,predictions)\n",
    "    _fn = fn(labels,predictions)\n",
    "    \n",
    "    return (_tp / (_tp+_fn))\n",
    "\n",
    "\n",
    "def f1_score(labels,predictions) :\n",
    "    pr = precision(labels,predictions)\n",
    "    re = recall(labels,predictions)\n",
    "    \n",
    "    return ((2*pr*re)/(pr+re))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "minus-capital",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given function performs feature transformation and make prediction on stream of data...\n",
    "def test_train(text) :\n",
    "    #i =0\n",
    "    global lr,prediction,label\n",
    "    if text.collect() != [] :\n",
    "        for data in text.collect() :\n",
    "            data = data.split('|')\n",
    "            #print(data)\n",
    "            feature = [float(data[0]),float(data[1]),data[2],float(data[3])]\n",
    "            #print(feature)\n",
    "            #print(feature)\n",
    "            Dframe = sc.parallelize([feature]).toDF(('timestamp','value','code','Class'))\n",
    "            df = model.transform(Dframe)\n",
    "            #print('---->',x.collect())\n",
    "            #print(x.select(['features_norm']).collect())\n",
    "            tempdf = lr.transform(df)\n",
    "            #if prediction is None and label is None : \n",
    "            prediction.append(tempdf.toPandas().pred_svc.values[0])\n",
    "            label.append(tempdf.toPandas().Class.values[0])\n",
    "            #print('pred :', prediction)\n",
    "            #print('label :',label)\n",
    "            #y2+=1\n",
    "            #print(y2)\n",
    "    else :\n",
    "        print('Empty!!!!')\n",
    "        try :\n",
    "            ssc.stop()\n",
    "        except Py4JJavaError() as err:\n",
    "            print(err)\n",
    "            print('Streaming Stopped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "continental-wrist",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc = StreamingContext(sc, 2)\n",
    "lines = ssc.socketTextStream('localhost', 9998)\n",
    "lines.foreachRDD(test_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "professional-society",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty!!!!\n"
     ]
    }
   ],
   "source": [
    "ssc.start()             # Start the streaming process\n",
    "ssc.awaitTermination()  # Wait for the streaming to end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "minus-being",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An utility function to evaluate the model on the prediction it makes....\n",
    "def classification_report(label,prediction) : \n",
    "    label_ = pd.Series(label)\n",
    "    prediction_ = pd.Series(prediction)\n",
    "    print('Accuracy : {}'.format(accuracy(label_,prediction_)))\n",
    "    print('Precision : {}'.format(precision(label_,prediction_)))\n",
    "    print('Recall : {}'.format(recall(label_,prediction_)))\n",
    "    print('f1-score : {}'.format(f1_score(label_,prediction_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "amateur-tennis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 1.0\n",
      "Precision : 1.0\n",
      "Recall : 1.0\n",
      "f1-score : 1.0\n"
     ]
    }
   ],
   "source": [
    "classification_report(label,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sublime-edwards",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
