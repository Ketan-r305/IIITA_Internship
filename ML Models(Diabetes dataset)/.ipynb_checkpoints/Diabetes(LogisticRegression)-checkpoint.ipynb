{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext.getOrCreate(SparkConf().setMaster(\"local[*]\"))\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (spark.read\n",
    "          .format(\"csv\")\n",
    "          .option('header', 'true')\n",
    "          .load(\"./datasets/uci-diabetes.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import Normalizer\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns  = df.columns\n",
    "\n",
    "dataset = df.select(col(columns[1]).cast('float'),\n",
    "                    col(columns[2]).cast('float'),\n",
    "                    col(columns[3]).cast('string'),\n",
    "                    col(columns[4]).cast('float'),\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = StringIndexer(inputCol=\"code\", outputCol=\"codeIndex\")\n",
    "encoder = OneHotEncoder(inputCol=\"codeIndex\", outputCol=\"codeVec\")\n",
    "vectorAssembler = VectorAssembler(inputCols=['value','codeVec'],\n",
    "                                  outputCol=\"features\")\n",
    "#normalizer = Normalizer(inputCol=\"features\", outputCol=\"features_norm\", p=1.0)\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"features_norm\")\n",
    "pipeline = Pipeline(stages=[indexer, encoder, vectorAssembler, scaler])\n",
    "final_df = pipeline.fit(dataset).transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(training_data, test_data) = final_df.randomSplit([0.8,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "param_grid = (ParamGridBuilder()\n",
    "              .baseOn({lr.labelCol : 'Class'})\n",
    "              .baseOn([lr.predictionCol, 'pred_lr'])\n",
    "              .baseOn([lr.featuresCol, 'features_norm'])\n",
    "              .addGrid(lr.regParam, [0.01,0.1,0,1,10,20])\n",
    "              .addGrid(lr.elasticNetParam, [0,0.25,0.75,1])\n",
    "              .addGrid(lr.fitIntercept, [True,False])\n",
    "              .addGrid(lr.maxIter, [10,100,1000])\n",
    "              .addGrid(lr.aggregationDepth, [2,5,10]).build())\n",
    "\n",
    "#evaluator1 = BinaryClassificationEvaluator(labelCol= 'Class',rawPredictionCol= 'pred_lr',metricName='areaUnderROC')\n",
    "evaluator2 = BinaryClassificationEvaluator(labelCol= 'Class',rawPredictionCol= 'pred_lr',metricName='areaUnderPR')\n",
    "\n",
    "\n",
    "#cv1 = CrossValidator(estimator=svc, estimatorParamMaps=param_grid, evaluator=evaluator1,seed=0,parallelism=2)\n",
    "cv2 = CrossValidator(estimator=lr, estimatorParamMaps=param_grid, evaluator=evaluator2,seed=0,parallelism=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvModel2 = cv2.fit(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999441289751798"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator2.evaluate(cvModel2.transform(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999260119862776"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator2.evaluate(cvModel2.transform(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvModel2.save('./SavedModel/lr_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import CrossValidatorModel\n",
    "\n",
    "model_path= r'.\\model\\lr_main_model_without_timestamp'\n",
    "cvModelRead = CrossValidatorModel.read().load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9998488797037863"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator2.evaluate(cvModelRead.transform(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
