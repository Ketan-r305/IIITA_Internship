{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext.getOrCreate(SparkConf().setMaster(\"local[*]\"))\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (spark.read\n",
    "          .format(\"csv\")\n",
    "          .option('header', 'true')\n",
    "          .load(\"./datasets/US-Chronic-dataset.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import Normalizer\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.feature import MinMaxScaler\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "from pyspark.ml.tuning import CrossValidatorModel\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Features and Casting it into required Dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns  = df.columns\n",
    "\n",
    "dataset = df.select(col(columns[3]).cast('string'),\n",
    "                    col(columns[4]).cast('string'),\n",
    "                    col(columns[5]).cast('string'),\n",
    "                    col(columns[6]).cast('float'),\n",
    "                    col(columns[7]).cast('float'),\n",
    "                    col(columns[8]).cast('float'),\n",
    "                    col(columns[9]).cast('string'),\n",
    "                    col(columns[10]).cast('string'),\n",
    "                    col(columns[11]).cast('string'),\n",
    "                    col(columns[12]).cast('string'),\n",
    "                    col(columns[13]).cast('string'),\n",
    "                    col(columns[14]).cast('float'),\n",
    "                    col(columns[15]).cast('float'),\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputCols for StringIndexer\n",
    "string_col = [\n",
    "    'DataSource','DataValueUnit','DataValueTypeID',\n",
    "    'QuestionID','LocationID','StratificationCategoryID1',\n",
    "    'StratificationID1','TopicID'\n",
    "]\n",
    "\n",
    "#outputCols for StringIndexer\n",
    "string_col_output = [\n",
    "    'DataSourceIndex','DataValueUnitIndex','DataValueTypeIDIndex',\n",
    "    'QuestionIDIndex','LocationIDIndex','StratificationCategoryID1Index',\n",
    "    'StratificationID1Index','TopicIDIndex'\n",
    "]\n",
    "\n",
    "#inputCols for OneHotEncoder\n",
    "string_col_encode_input = [\n",
    "    'DataSourceIndex','DataValueUnitIndex','DataValueTypeIDIndex',\n",
    "    'QuestionIDIndex','LocationIDIndex','StratificationCategoryID1Index',\n",
    "    'StratificationID1Index'\n",
    "]\n",
    "\n",
    "#outputCols for OneHotEncoder\n",
    "string_col_encoded = [\n",
    "    'DataSourceVec','DataValueUnitVec','DataValueTypeIDVec',\n",
    "    'QuestionIDVec','LocationIDVec','StratificationCategoryID1Vec',\n",
    "    'StratificationID1Vec'\n",
    "]\n",
    "\n",
    "#inputCols for VectorAssembler\n",
    "features_to_assemble = string_col_encoded + ['DataValue','LowConfidenceLimit','HighConfidenceLimit','Geo_lat','Geo_lon']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = StringIndexer(inputCols= string_col, outputCols=string_col_output)\n",
    "encoder = OneHotEncoder(inputCols=string_col_encode_input, outputCols=string_col_encoded)\n",
    "vectorAssembler = VectorAssembler(inputCols=features_to_assemble,\n",
    "                                  outputCol=\"features\")\n",
    "normalizer = Normalizer(inputCol=\"features\", outputCol=\"features_norm\", p=1.0)\n",
    "scaler = StandardScaler(inputCol=\"features_norm\", outputCol=\"features_norm_scaled\")\n",
    "pipeline = Pipeline(stages=[indexer, encoder, vectorAssembler, normalizer,scaler])\n",
    "final_df = pipeline.fit(dataset).transform(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Dataset into training data and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "(training_data, test_data) = final_df.randomSplit([0.8,0.2],seed=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier()\n",
    "param_grid = (ParamGridBuilder()\n",
    "              .baseOn({dtc.labelCol : 'TopicIDIndex'})\n",
    "              .baseOn([dtc.predictionCol, 'pred_dtc'])\n",
    "              .baseOn([dtc.featuresCol, 'features_norm'])\n",
    "              .addGrid(dtc.impurity, ['entropy','gini'])\n",
    "              .addGrid(dtc.maxBins, [32,64])\n",
    "              .addGrid(dtc.maxDepth, [20,25,30]).build())\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol= 'TopicIDIndex',predictionCol= 'pred_dtc')\n",
    "\n",
    "cv = CrossValidator(estimator=dtc, estimatorParamMaps=param_grid, evaluator=evaluator,seed=0,parallelism=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvModel = cv.fit(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8530009744828864,\n",
       " 0.9100120508156919,\n",
       " 0.948191757209137,\n",
       " 0.8592219013495861,\n",
       " 0.9119071206541041,\n",
       " 0.9476137587294395,\n",
       " 0.6694895371311423,\n",
       " 0.709777237583297,\n",
       " 0.7422881343771186,\n",
       " 0.6588639874944618,\n",
       " 0.7022554930149069,\n",
       " 0.734393853379154]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvModel.avgMetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Trained Model using different evaluation metrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9529846241255637"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(cvModel.transform(test_data),{evaluator.metricName: \"accuracy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9545460913261533"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(cvModel.transform(test_data),{evaluator.metricName: \"f1\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(cvModel.transform(test_data),{evaluator.metricName: \"precisionByLabel\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9586648554240248"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(cvModel.transform(test_data),{evaluator.metricName: \"recallByLabel\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'entropy'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvModel.bestModel.getImpurity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvModel.bestModel.getMaxBins()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvModel.bestModel.getMaxDepth()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "path= r'./SavedModels/DTClassifier_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvModel.save(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dtc_model = CrossValidatorModel.read().load(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy     0.952985\n",
       "f1-score     0.954546\n",
       "precision    1.000000\n",
       "recall       0.958665\n",
       "dtype: float64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "summary_={\n",
    "    'accuracy' : 0.9529846241255637,\n",
    "    'f1-score' : 0.9545460913261533,\n",
    "    'precision' : 1.0,\n",
    "    'recall' : 0.9586648554240248\n",
    "}\n",
    "\n",
    "summary = pd.Series(summary_)\n",
    "summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
