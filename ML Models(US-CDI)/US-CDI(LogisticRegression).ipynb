{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext.getOrCreate(SparkConf().setMaster(\"local[*]\"))\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (spark.read\n",
    "          .format(\"csv\")\n",
    "          .option('header', 'true')\n",
    "          .load(\"./datasets/US-Chronic-dataset.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import Normalizer\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.feature import MinMaxScaler\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "from pyspark.ml.tuning import CrossValidatorModel\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Features and Casting it into required Dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns  = df.columns\n",
    "\n",
    "dataset = df.select(col(columns[3]).cast('string'),\n",
    "                    col(columns[4]).cast('string'),\n",
    "                    col(columns[5]).cast('string'),\n",
    "                    col(columns[6]).cast('float'),\n",
    "                    col(columns[7]).cast('float'),\n",
    "                    col(columns[8]).cast('float'),\n",
    "                    col(columns[9]).cast('string'),\n",
    "                    col(columns[10]).cast('string'),\n",
    "                    col(columns[11]).cast('string'),\n",
    "                    col(columns[12]).cast('string'),\n",
    "                    col(columns[13]).cast('string'),\n",
    "                    col(columns[14]).cast('float'),\n",
    "                    col(columns[15]).cast('float'),\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputCols for StringIndexer\n",
    "string_col = [\n",
    "    'DataSource','DataValueUnit','DataValueTypeID',\n",
    "    'QuestionID','LocationID','StratificationCategoryID1',\n",
    "    'StratificationID1','TopicID'\n",
    "]\n",
    "\n",
    "#outputCols for StringIndexer\n",
    "string_col_output = [\n",
    "    'DataSourceIndex','DataValueUnitIndex','DataValueTypeIDIndex',\n",
    "    'QuestionIDIndex','LocationIDIndex','StratificationCategoryID1Index',\n",
    "    'StratificationID1Index','TopicIDIndex'\n",
    "]\n",
    "\n",
    "#inputCols for OneHotEncoder\n",
    "string_col_encode_input = [\n",
    "    'DataSourceIndex','DataValueUnitIndex','DataValueTypeIDIndex',\n",
    "    'QuestionIDIndex','LocationIDIndex','StratificationCategoryID1Index',\n",
    "    'StratificationID1Index'\n",
    "]\n",
    "\n",
    "#outputCols for OneHotEncoder\n",
    "string_col_encoded = [\n",
    "    'DataSourceVec','DataValueUnitVec','DataValueTypeIDVec',\n",
    "    'QuestionIDVec','LocationIDVec','StratificationCategoryID1Vec',\n",
    "    'StratificationID1Vec'\n",
    "]\n",
    "\n",
    "#inputCols for VectorAssembler\n",
    "features_to_assemble = string_col_encoded + ['DataValue','LowConfidenceLimit','HighConfidenceLimit','Geo_lat','Geo_lon']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = StringIndexer(inputCols= string_col, outputCols=string_col_output)\n",
    "encoder = OneHotEncoder(inputCols=string_col_encode_input, outputCols=string_col_encoded)\n",
    "vectorAssembler = VectorAssembler(inputCols=features_to_assemble,\n",
    "                                  outputCol=\"features\")\n",
    "normalizer = Normalizer(inputCol=\"features\", outputCol=\"features_norm\", p=1.0)\n",
    "scaler = StandardScaler(inputCol=\"features_norm\", outputCol=\"features_norm_scaled\")\n",
    "pipeline = Pipeline(stages=[indexer, encoder, vectorAssembler, normalizer,scaler])\n",
    "final_df = pipeline.fit(dataset).transform(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the Dataset into training data and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "(training_data, test_data) = final_df.randomSplit([0.8,0.2],seed=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "param_grid = (ParamGridBuilder()\n",
    "              .baseOn({lr.labelCol : 'TopicIDIndex'})\n",
    "              .baseOn([lr.predictionCol, 'pred_lr'])\n",
    "              .baseOn([lr.featuresCol, 'features_norm'])\n",
    "              .addGrid(lr.regParam, [0.01,0.1,1,10])\n",
    "              .addGrid(lr.elasticNetParam, [0,1]).build())\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol= 'TopicIDIndex',predictionCol= 'pred_lr')\n",
    "\n",
    "cv = CrossValidator(estimator=lr, estimatorParamMaps=param_grid, evaluator=evaluator,seed=0,parallelism=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvModel = cv.fit(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9996875851432031,\n",
       " 0.9984307026779189,\n",
       " 0.9972442973636216,\n",
       " 0.2802655989286207,\n",
       " 0.7354145793579145,\n",
       " 0.05632048517561031,\n",
       " 0.05637507702995426,\n",
       " 0.05632048517561031]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvModel.avgMetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the Trained Model Using Different Evaluation Metrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9996093888711338"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(cvModel.transform(test_data),{evaluator.metricName: \"accuracy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9996092480230769"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(cvModel.transform(test_data),{evaluator.metricName: \"f1\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9978698683191325"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(cvModel.transform(test_data),{evaluator.metricName: \"precisionByLabel\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(cvModel.transform(test_data),{evaluator.metricName: \"recallByLabel\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvModel.bestModel.getRegParam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvModel.bestModel.getElasticNetParam()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "path= r'./SavedModels/lr_model'\n",
    "cvModel.save(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lr_model = CrossValidatorModel.read().load(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy     0.999609\n",
       "f1-score     0.999609\n",
       "precision    0.997870\n",
       "recall       1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "summary_={\n",
    "    'accuracy' : 0.9996093888711338,\n",
    "    'f1-score' : 0.9996092480230769,\n",
    "    'precision' : 0.9978698683191325,\n",
    "    'recall' : 1.0\n",
    "}\n",
    "\n",
    "summary = pd.Series(summary_)\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
