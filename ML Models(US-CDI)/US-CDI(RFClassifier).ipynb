{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext.getOrCreate(SparkConf().setMaster(\"local[*]\"))\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (spark.read\n",
    "          .format(\"csv\")\n",
    "          .option('header', 'true')\n",
    "          .load(\"./datasets/US-Chronic-dataset.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import Normalizer\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.feature import MinMaxScaler\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "from pyspark.ml.tuning import CrossValidatorModel\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.evaluation import MultilabelClassificationEvaluator\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Features and Casting it into required Dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns  = df.columns\n",
    "\n",
    "dataset = df.select(col(columns[3]).cast('string'),\n",
    "                    col(columns[4]).cast('string'),\n",
    "                    col(columns[5]).cast('string'),\n",
    "                    col(columns[6]).cast('float'),\n",
    "                    col(columns[7]).cast('float'),\n",
    "                    col(columns[8]).cast('float'),\n",
    "                    col(columns[9]).cast('string'),\n",
    "                    col(columns[10]).cast('string'),\n",
    "                    col(columns[11]).cast('string'),\n",
    "                    col(columns[12]).cast('string'),\n",
    "                    col(columns[13]).cast('string'),\n",
    "                    col(columns[14]).cast('float'),\n",
    "                    col(columns[15]).cast('float'),\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputCols for StringIndexer\n",
    "string_col = [\n",
    "    'DataSource','DataValueUnit','DataValueTypeID',\n",
    "    'QuestionID','LocationID','StratificationCategoryID1',\n",
    "    'StratificationID1','TopicID'\n",
    "]\n",
    "\n",
    "#outputCols for StringIndexer\n",
    "string_col_output = [\n",
    "    'DataSourceIndex','DataValueUnitIndex','DataValueTypeIDIndex',\n",
    "    'QuestionIDIndex','LocationIDIndex','StratificationCategoryID1Index',\n",
    "    'StratificationID1Index','TopicIDIndex'\n",
    "]\n",
    "\n",
    "#inputCols for OneHotEncoder\n",
    "string_col_encode_input = [\n",
    "    'DataSourceIndex','DataValueUnitIndex','DataValueTypeIDIndex',\n",
    "    'QuestionIDIndex','LocationIDIndex','StratificationCategoryID1Index',\n",
    "    'StratificationID1Index'\n",
    "]\n",
    "\n",
    "#outputCols for OneHotEncoder\n",
    "string_col_encoded = [\n",
    "    'DataSourceVec','DataValueUnitVec','DataValueTypeIDVec',\n",
    "    'QuestionIDVec','LocationIDVec','StratificationCategoryID1Vec',\n",
    "    'StratificationID1Vec'\n",
    "]\n",
    "\n",
    "#inputCols for VectorAssembler\n",
    "features_to_assemble = string_col_encoded + ['DataValue','LowConfidenceLimit','HighConfidenceLimit','Geo_lat','Geo_lon']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = StringIndexer(inputCols= string_col, outputCols=string_col_output)\n",
    "encoder = OneHotEncoder(inputCols=string_col_encode_input, outputCols=string_col_encoded)\n",
    "vectorAssembler = VectorAssembler(inputCols=features_to_assemble,\n",
    "                                  outputCol=\"features\")\n",
    "normalizer = Normalizer(inputCol=\"features\", outputCol=\"features_norm\", p=1.0)\n",
    "scaler = StandardScaler(inputCol=\"features_norm\", outputCol=\"features_norm_scaled\")\n",
    "pipeline = Pipeline(stages=[indexer, encoder, vectorAssembler, normalizer,scaler])\n",
    "final_df = pipeline.fit(dataset).transform(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the Dataset into Training data and Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "(training_data, test_data) = final_df.randomSplit([0.8,0.2],seed=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "param_grid = (ParamGridBuilder()\n",
    "              .baseOn({rfc.labelCol : 'TopicIDIndex'})\n",
    "              .baseOn([rfc.predictionCol, 'pred_rfc'])\n",
    "              .baseOn([rfc.featuresCol, 'features_norm'])\n",
    "              .addGrid(rfc.maxDepth, [7,10,15,20,30]).build())\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol= 'TopicIDIndex',predictionCol= 'pred_rfc')\n",
    "\n",
    "cv = CrossValidator(estimator=rfc, estimatorParamMaps=param_grid, evaluator=evaluator,seed=0,parallelism=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvModel = cv.fit(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6973069875602796,\n",
       " 0.8017472531901317,\n",
       " 0.8840126290184793,\n",
       " 0.948660583153587,\n",
       " 0.9874816855658695]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvModel.avgMetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the Model Using Different Evaluation Metrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9863996306949327"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(cvModel.transform(test_data),{evaluator.metricName: \"accuracy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9863540681712097"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(cvModel.transform(test_data),{evaluator.metricName: \"f1\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9994152046783625"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(cvModel.transform(test_data),{evaluator.metricName: \"precisionByLabel\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9949543954977683"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(cvModel.transform(test_data),{evaluator.metricName: \"recallByLabel\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvModel.bestModel.getMaxDepth()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "path= r'./SavedModels/RFClassifier_model'\n",
    "cvModel.save(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rfc_model = CrossValidatorModel.read().load(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy     0.986400\n",
       "f1-score     0.986354\n",
       "precision    0.999415\n",
       "recall       0.994954\n",
       "dtype: float64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "summary_={\n",
    "    'accuracy' : 0.9863996306949327,\n",
    "    'f1-score' : 0.9863540681712097,\n",
    "    'precision' : 0.9994152046783625,\n",
    "    'recall' : 0.9949543954977683\n",
    "}\n",
    "\n",
    "summary = pd.Series(summary_)\n",
    "summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
